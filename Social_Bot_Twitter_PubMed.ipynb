{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Social Bot from PubMed.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPE3o7FnBx2SuGmo4610sue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PineBiotech/bioinformatics/blob/master/Social_Bot_Twitter_PubMed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First install tweepy (all installations should only be needed once per session)"
      ],
      "metadata": {
        "id": "Me4uwN3Bw8E9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TdIQ65xwLAv",
        "outputId": "40c8df2c-9acc-498c-8527-012a50bfb8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        " pip install tweepy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where app keys are set through our twitter developer profile"
      ],
      "metadata": {
        "id": "9-huXQUc7Vje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_key = \"___\" #api key\n",
        "consumer_secret = \"___\" #api key secret\n",
        "access_token = \"___\"\n",
        "access_token_secret = \"___\"\n"
      ],
      "metadata": {
        "id": "dXHyGIS96zFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "authorization step (once per session only)"
      ],
      "metadata": {
        "id": "7u2mPEj-7bP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "# Authenticate to Twitter\n",
        "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
        "auth.set_access_token(access_token,access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n"
      ],
      "metadata": {
        "id": "GktRccvUwSXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check authorization"
      ],
      "metadata": {
        "id": "meFPSt2c7fbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    api.verify_credentials()\n",
        "    print(\"Authentication OK\")\n",
        "except:\n",
        "    print(\"Error during authentication\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyFVF2cPxbr3",
        "outputId": "583d0101-b1e2-4eb3-fe99-f5548cf5b84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create API object\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True,\n",
        "    wait_on_rate_limit_notify=True)"
      ],
      "metadata": {
        "id": "znSM-UJWxkN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First script is to find users based on a search term"
      ],
      "metadata": {
        "id": "JqUfu6Cp7k6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Retweet and follow users based on search term\n",
        "\n",
        "for tweet in api.search(q=\"microbiome analysis\", lang=\"en\", rpp=1):\n",
        "\n",
        "  followstat = \"now following \"\n",
        "\n",
        "  mytweet = f\"RT @{tweet.user.screen_name} {tweet.text} #bioinformatics #omicslogic\"\n",
        "  user = [\"@\",tweet.user.screen_name, tweet.user.location]\n",
        "  print(mytweet)\n",
        "  #print(tweet.user.screen_name)\n",
        "  user = api.get_user(tweet.user.screen_name)\n",
        "  print(user.id)\n",
        "\n",
        "  # Tweet something\n",
        "  status = api.update_status(mytweet)\n",
        "\n",
        "  # Like the tweet you just made\n",
        "  api.create_favorite(tweet.id)\n",
        "\n",
        "  api.create_friendship(user.id)\n"
      ],
      "metadata": {
        "id": "0o7wy3GeyfeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find and like tweets based on a term"
      ],
      "metadata": {
        "id": "TEKHW2ux7qg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#like a tweet based on a search term\n",
        "\n",
        "search_string=\"bioinformatics education\"                            #String you want to search\n",
        "numberoftweets=5                                       #number of tweets you want to like\n",
        "for tweet in tweepy.Cursor(api.search,search_string).items(numberoftweets):\n",
        "    try:\n",
        "        tweet.favorite()\n",
        "        print(\"I liked the tweet %s\"%tweet.text)  #print statement for us to know that bot has liked the tweets successfully\n",
        "    except tweepy.TweepError as e:\n",
        "        print(e.reason)            #exception of tweep error and also prints the error reason\n",
        "    except StopIteration:\n",
        "        break                        #exception for iteration error and breaks the iteration"
      ],
      "metadata": {
        "id": "uLA3q8cK3vQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "This second part is to access publications on NCBI (PubMed) and prepare a short summary of a publication abstract"
      ],
      "metadata": {
        "id": "fkanL-6p7uix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install biopython"
      ],
      "metadata": {
        "id": "s7n7q3H3JwSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "retrieve article and get link, abstract. More options: https://biopython.org/docs/1.75/api/Bio.Medline.html"
      ],
      "metadata": {
        "id": "CsZeEkA-78Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Biopython to retrieve the latest article from pubmed on query term\n",
        "\n",
        "import pandas as pd\n",
        "from Bio import Medline,Entrez\n",
        "\n",
        "#Bio.Medline.read(handle)\n",
        "Entrez.email = '_____'\n",
        "\n",
        "query = 'bioinformatics AND pipeline'\n",
        "   \n",
        "handle = Entrez.esearch(db=\"pubmed\",term=query, sort=\"date\")\n",
        "record=Entrez.read(handle)\n",
        "idlist=record[\"IdList\"]\n",
        "\n",
        "# Search, using history results if cached before\n",
        "#records = Entrez.read(handle)\n",
        "handle = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\",retmode=\"text\")\n",
        "records = Medline.parse(handle)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for record in records:\n",
        "  abstract = []\n",
        "  abstract.append(record.get(\"AB\",\"?\"))\n",
        "  author = record.get(\"AID\",\"?\")\n",
        "  print(abstract)\n",
        "  arlink1 = []\n",
        "  arlink1.append(\"https://pubmed.ncbi.nlm.nih.gov/%s\"%idlist[i])\n",
        "  print(arlink1)\n",
        "  #print(idlist[i])\n",
        "  i = i+1\n",
        "\n",
        "#get all links \n",
        "len(arlink1)\n",
        "\n",
        "for i in range(len(idlist)):\n",
        "  arlink1.append(\"https://pubmed.ncbi.nlm.nih.gov/%s\"%idlist[i])\n",
        "\n",
        "#print(arlink1)\n",
        "\n",
        "#print only the latest link\n",
        "this_id = idlist[i]\n",
        "\n",
        "#print the last article link\n",
        "arlink = \"https://pubmed.ncbi.nlm.nih.gov/%s\"%this_id\n",
        "print(arlink)\n"
      ],
      "metadata": {
        "id": "a19H_t34J37W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(i)\n",
        "\n",
        "#print only the latest link\n",
        "this_id = idlist[i]\n",
        "\n",
        "#print the last article link\n",
        "arlink = \"https://pubmed.ncbi.nlm.nih.gov/%s\"%this_id\n",
        "print(arlink1)"
      ],
      "metadata": {
        "id": "X07VOSseaYHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, we use the Google T5: Text-To-Text Transfer Transformer (https://github.com/google-research/text-to-text-transfer-transformer)"
      ],
      "metadata": {
        "id": "ExQjX-2j8KHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "_xN7QeOiSTwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First load in the article abstract"
      ],
      "metadata": {
        "id": "-xXoX9wn8SrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(abstract)"
      ],
      "metadata": {
        "id": "3eEkrABaG2L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
        "model = AutoModelWithLMHead.from_pretrained('t5-base', return_dict=True)\n",
        "\n",
        "inputs = tokenizer.encode(\"summarize: \" + abstract[0],\n",
        "                          return_tensors='pt',\n",
        "                          max_length=1000,\n",
        "                          truncation=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVLjHDMfR37b",
        "outputId": "84435123-4b95-48ff-d789-d84cc70ce709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:882: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now generate summary given a limited number of characters"
      ],
      "metadata": {
        "id": "t0o9muQE8YHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_ids = model.generate(inputs, max_length=30, min_length=20, length_penalty=5., num_beams=2)\n",
        "\n",
        "summary = tokenizer.decode(summary_ids[0])\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq7sZhokSN20",
        "outputId": "a9724e66-8f79-4a00-fd18-f642e388afc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> long-read RNA sequencing provides full-length transcripts which can be used to predict full-length protein isoforms. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean up the text, add link and tweet"
      ],
      "metadata": {
        "id": "vh2xcQyn8cB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summary.replace('<pad>', '')\n",
        "cleansum = summary.replace('</s>', '')\n",
        "\n",
        "mytweet1 = \"#sequencing:%s read more: %s\" % (summary, arlink)\n",
        "print(mytweet1)\n",
        "  \n",
        "# Tweet something\n",
        "status = api.update_status(mytweet1)\n",
        "\n",
        "# Like the tweet you just made\n",
        "#api.create_favorite(tweet.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syjuEDJTqAva",
        "outputId": "8d2947e2-df94-420e-cb40-01aa8d102c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#sequencing: long-read RNA sequencing provides full-length transcripts which can be used to predict full-length protein isoforms.  read more: https://pubmed.ncbi.nlm.nih.gov/35241129\n"
          ]
        }
      ]
    }
  ]
}